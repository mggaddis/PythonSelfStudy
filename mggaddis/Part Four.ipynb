{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('C:\\Users\\mgaddis\\Documents\\GitHub\\Data\\NCAA\\RegularSeasonDetailedResults - Train.csv')\n",
    "test=pd.read_csv('C:\\Users\\mgaddis\\Documents\\GitHub\\Data\\NCAA\\RegularSeasonDetailedResults - Test.csv')\n",
    "train['Type']='Train' #Create a flag for Train and Test Data set\n",
    "test['Type']='Test'\n",
    "fullData = pd.concat([train,test],axis=0) #Combined both Train and Test Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Season  Daynum  Wteam  Wscore  Lteam  Lscore Wloc  Numot  Wfgm  Wfga  \\\n",
      "0    2003      10   1104      68   1328      62    N      0    27    58   \n",
      "1    2003      10   1272      70   1393      63    N      0    26    62   \n",
      "2    2003      11   1266      73   1437      61    N      0    24    58   \n",
      "3    2003      11   1296      56   1457      50    N      0    18    38   \n",
      "4    2003      11   1400      77   1208      71    N      0    30    61   \n",
      "5    2003      11   1458      81   1186      55    H      0    26    57   \n",
      "6    2003      12   1161      80   1236      62    H      0    23    55   \n",
      "7    2003      12   1186      75   1457      61    N      0    28    62   \n",
      "8    2003      12   1194      71   1156      66    N      0    28    58   \n",
      "9    2003      12   1458      84   1296      56    H      0    32    67   \n",
      "\n",
      "   ...    Lftm  Lfta  Lor  Ldr  Last  Lto  Lstl  Lblk  Lpf   Type  \n",
      "0  ...      16    22   10   22     8   18     9     2   20  Train  \n",
      "1  ...       9    20   20   25     7   12     8     6   16  Train  \n",
      "2  ...      14    23   31   22     9   12     2     5   23  Train  \n",
      "3  ...       8    15   17   20     9   19     4     3   23  Train  \n",
      "4  ...      17    27   21   15    12   10     7     1   14  Train  \n",
      "5  ...      12    17    6   22     8   19     4     3   25  Train  \n",
      "6  ...      20    28    9   21    11   30    10     4   28  Train  \n",
      "7  ...      17    23    8   25    10   15    14     8   18  Train  \n",
      "8  ...      12    27   13   26    13   25     8     2   18  Train  \n",
      "9  ...       7    12    9   23    10   18     1     3   18  Train  \n",
      "\n",
      "[10 rows x 35 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Daynum</th>\n",
       "      <th>Wteam</th>\n",
       "      <th>Wscore</th>\n",
       "      <th>Lteam</th>\n",
       "      <th>Lscore</th>\n",
       "      <th>Numot</th>\n",
       "      <th>Wfgm</th>\n",
       "      <th>Wfga</th>\n",
       "      <th>Wfgm3</th>\n",
       "      <th>...</th>\n",
       "      <th>Lfga3</th>\n",
       "      <th>Lftm</th>\n",
       "      <th>Lfta</th>\n",
       "      <th>Lor</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lstl</th>\n",
       "      <th>Lblk</th>\n",
       "      <th>Lpf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65872.00000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "      <td>65872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2009.19670</td>\n",
       "      <td>71.485942</td>\n",
       "      <td>1286.705884</td>\n",
       "      <td>74.429150</td>\n",
       "      <td>1282.259716</td>\n",
       "      <td>62.461380</td>\n",
       "      <td>0.071806</td>\n",
       "      <td>25.733453</td>\n",
       "      <td>54.493396</td>\n",
       "      <td>6.795315</td>\n",
       "      <td>...</td>\n",
       "      <td>18.837336</td>\n",
       "      <td>12.113796</td>\n",
       "      <td>18.030605</td>\n",
       "      <td>11.227805</td>\n",
       "      <td>21.072474</td>\n",
       "      <td>11.379736</td>\n",
       "      <td>14.562910</td>\n",
       "      <td>6.119186</td>\n",
       "      <td>2.864616</td>\n",
       "      <td>19.818314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.70925</td>\n",
       "      <td>35.181219</td>\n",
       "      <td>104.946668</td>\n",
       "      <td>11.026665</td>\n",
       "      <td>104.117659</td>\n",
       "      <td>10.819419</td>\n",
       "      <td>0.312054</td>\n",
       "      <td>4.668628</td>\n",
       "      <td>7.595760</td>\n",
       "      <td>2.959497</td>\n",
       "      <td>...</td>\n",
       "      <td>5.749657</td>\n",
       "      <td>5.349949</td>\n",
       "      <td>7.146710</td>\n",
       "      <td>4.249908</td>\n",
       "      <td>4.747957</td>\n",
       "      <td>3.724221</td>\n",
       "      <td>4.484467</td>\n",
       "      <td>2.799324</td>\n",
       "      <td>2.050325</td>\n",
       "      <td>4.519672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2003.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2006.00000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1191.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2009.00000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1285.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1281.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2012.00000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1379.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2015.00000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Season        Daynum         Wteam        Wscore         Lteam  \\\n",
       "count  65872.00000  65872.000000  65872.000000  65872.000000  65872.000000   \n",
       "mean    2009.19670     71.485942   1286.705884     74.429150   1282.259716   \n",
       "std        3.70925     35.181219    104.946668     11.026665    104.117659   \n",
       "min     2003.00000      0.000000   1101.000000     34.000000   1101.000000   \n",
       "25%     2006.00000     40.000000   1196.000000     67.000000   1191.000000   \n",
       "50%     2009.00000     75.000000   1285.000000     74.000000   1281.000000   \n",
       "75%     2012.00000    102.000000   1379.000000     81.000000   1374.000000   \n",
       "max     2015.00000    132.000000   1464.000000    142.000000   1464.000000   \n",
       "\n",
       "             Lscore         Numot          Wfgm          Wfga         Wfgm3  \\\n",
       "count  65872.000000  65872.000000  65872.000000  65872.000000  65872.000000   \n",
       "mean      62.461380      0.071806     25.733453     54.493396      6.795315   \n",
       "std       10.819419      0.312054      4.668628      7.595760      2.959497   \n",
       "min       20.000000      0.000000     10.000000     27.000000      0.000000   \n",
       "25%       55.000000      0.000000     22.000000     49.000000      5.000000   \n",
       "50%       62.000000      0.000000     25.000000     54.000000      7.000000   \n",
       "75%       69.000000      0.000000     29.000000     59.000000      9.000000   \n",
       "max      140.000000      6.000000     49.000000    103.000000     24.000000   \n",
       "\n",
       "           ...              Lfga3          Lftm          Lfta           Lor  \\\n",
       "count      ...       65872.000000  65872.000000  65872.000000  65872.000000   \n",
       "mean       ...          18.837336     12.113796     18.030605     11.227805   \n",
       "std        ...           5.749657      5.349949      7.146710      4.249908   \n",
       "min        ...           1.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...          15.000000      8.000000     13.000000      8.000000   \n",
       "50%        ...          18.000000     12.000000     17.000000     11.000000   \n",
       "75%        ...          22.000000     15.000000     23.000000     14.000000   \n",
       "max        ...          54.000000     42.000000     61.000000     36.000000   \n",
       "\n",
       "                Ldr          Last           Lto          Lstl          Lblk  \\\n",
       "count  65872.000000  65872.000000  65872.000000  65872.000000  65872.000000   \n",
       "mean      21.072474     11.379736     14.562910      6.119186      2.864616   \n",
       "std        4.747957      3.724221      4.484467      2.799324      2.050325   \n",
       "min      -23.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       18.000000      9.000000     11.000000      4.000000      1.000000   \n",
       "50%       21.000000     11.000000     14.000000      6.000000      3.000000   \n",
       "75%       24.000000     14.000000     17.000000      8.000000      4.000000   \n",
       "max       49.000000     31.000000     41.000000     22.000000     18.000000   \n",
       "\n",
       "                Lpf  \n",
       "count  65872.000000  \n",
       "mean      19.818314  \n",
       "std        4.519672  \n",
       "min        5.000000  \n",
       "25%       17.000000  \n",
       "50%       20.000000  \n",
       "75%       23.000000  \n",
       "max       45.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData.columns # This will show all the column names\n",
    "print(fullData.head(10)) # Show first 10 records of dataframe\n",
    "fullData.describe() #You can look at summary of numerical fields by using describe() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_col = ['Wteam']\n",
    "target_col = [\"Wscore\"]\n",
    "cat_cols = ['Season','Daynum']\n",
    "num_cols = list(set(list(fullData.columns))-set(cat_cols)-set(ID_col)-set(target_col))\n",
    "other_col = ['Type'] #Test and Train Data set identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#create label encoders for categorical features\n",
    "for var in cat_cols:\n",
    " number = LabelEncoder()\n",
    " fullData[var] = number.fit_transform(fullData[var].astype('str'))\n",
    "\n",
    "train=fullData[fullData['Type']=='Train']\n",
    "test=fullData[fullData['Type']=='Test']\n",
    "\n",
    "train['is_train'] = np.random.uniform(0, 1, len(train)) <= .75\n",
    "Train, Validate = train[train['is_train']==True], train[train['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=list(set(list(fullData.columns))-set(ID_col)-set(target_col)-set(other_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = Train[list(features)].values\n",
    "y_train = Train[\"Wscore\"].values\n",
    "x_validate = Validate[list(features)].values\n",
    "y_validate = Validate[\"Wscore\"].values\n",
    "x_test=test[list(features)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: N",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3fb6e6a739b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m    211\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    371\u001b[0m                                       force_all_finite)\n\u001b[0;32m    372\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: N"
     ]
    }
   ],
   "source": [
    "random.seed(100)\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
